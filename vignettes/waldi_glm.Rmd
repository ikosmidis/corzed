---
title: "Location-adjusted Wald statistics for generalized linear models"
author: "[Ioannis Kosmidis](http://www.ucl.ac.uk/~ucakiko/), Claudia Di Caterina"
date:  "`r format(Sys.time(), '%d %B, %Y')`"
output: rmarkdown::html_vignette
bibliography: corzed_2.bib
vignette: >
  %\VignetteIndexEntry{Location-adjusted Wald statistics in generalized linear models}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

## The **waldi** R package
The [**waldi**](https://github.com/ikosmidis/waldi) R package 
implements the computation of the location-adjusted Wald 
statistics derived in @dikos18 for `glm`, `brglmFit` and 
`betareg` objects, with corresponding methods for 
location-adjusted Wald confidence intervals. 
This vignette is a demo of the tools available for `glm` and 
`brglmFit` objects.

## The Wald statistics in generalized linear models
In generalized linear models (GLMs) [@mcculnel89], the 
expectation $\mu_i$ of the response $Y_i$ $(i=1,\dots,n)$ 
is linked to the $k$-vector of covariates $x_i$ as 
$g(\mu_i) = \beta^\top x_i$, where $g(.)$ is a suitable 
link function. The variance of $Y_i$ equals 
$\phi V(\mu_i) /m_i$, with $m_i\geq 0$ observation 
weight and $\phi$ dispersion parameter.

<!--The expected
information matrix on $\bbeta$ and $\phi$ is
\begin{equation}
  \label{eq:info}
 \bi(\bbeta, \phi)= \left[
    \begin{array}{cc}
      \frac{1}{\phi} \bX^\top \bW(\bbeta) \bX & 0_k \\
      0_k^\top & \frac{1}{2\phi^4}\sum_{i = 1}^n m_i^2 a''_i(-m_i/\phi)
    \end{array}
  \right]\,,
\end{equation}
where $0_k$ is a $k$-dimensional vector of zeros,
$a''(u) = d^2 a(u)/d u^2$, $\bX$ is the $n \times k$ model matrix with
rows $x_1, \ldots, x_n$ and
$\bW = {\rm diag}\left\{w_1, \ldots, w_n\right\}$ with
$w_i = m_i d_i^2/V(\mu_i)$, $d_i = d\mu_i/d\eta_i$.-->

The Wald statistic for testing $H_0: \beta_j=\beta_{j0}$ 
$(j=1,\dots,k)$ takes the form
$t_j = (\hat\beta_j - \beta_{j0})/\kappa_j(\hat\beta, \hat\phi)$,
where $\hat\beta$ and $\hat\phi$ are the maximum likelihood 
estimates for $\beta$ and $\phi$, and $\kappa_j(\beta, \phi)$ 
denotes the $(j, j)$th element in the $\beta$-block of the 
inverse of the 
[expected information](https://en.wikipedia.org/wiki/Fisher_information) 
$i(\beta, \phi)$ [@dikos18, Section 8].
The maximum likelihood estimator $\hat\phi$ is severely biased 
and not robust under mis-specification of the model [@mcculnel89]. 
When $\phi$ is unknown, `summary.glm` substitutes by default
in the expression of $t_j$ the moment estimator of $\phi$ based 
on the Pearson residuals.

Alternatively, the Wald statistic $\tilde{t}_j$ can be obtained 
by using the reduced-bias estimates of $\beta$ and $\phi$. The
function `summary.brglmFit` in the R package returns these values.

For instance, consider the crying babies data, available in the 
[**waldi**](https://github.com/ikosmidis/waldi) R package.  
```{r echo = TRUE}
library("waldi")
data("babies", package = "waldi")
head(babies)
```

Fitting a logistic regression to this dataset using maximum likelihood results in
```{r echo = TRUE}
babies_ml <- glm(formula = y ~ day + lull - 1, family = binomial, data = babies)
summary(babies_ml)
```
where the dispersion parameter is assumed $\phi=1$.
Here the interest is in testing the effect of lulling (`lullyes`) 
on the crying of children (`y`). The observed value $t=t_{19}=1.951$ 
implies a $p$-value almost significant against the hypothesis of
no effect of lulling at a 5% level.

The following chunk gives the same fit with mean bias-reduced estimates:
```{r echo = TRUE}
library("brglm2")
babies_br <- update(babies_ml, method = "brglmFit")
summary(babies_br)
```
Here $\tilde{t}=\tilde{t}_{19}=1.736$, with a $p$-value far above 
the significance level.

## Location-adjusted Wald statistics
It is well-known that the standard normal approximation to 
the distribution of $t_j$ can be inadequate when the sample 
size is small or moderate relative to the number of parameters.
@dikos18 recommend to use in its place the location-adjusted 
statistic $t_j^*= t_j - \hat B$, where 
$\hat B=B(\hat\beta, \hat\phi; \beta_{0j})$ is a correction 
involving the 
[expected information](https://en.wikipedia.org/wiki/Fisher_information), 
an approximation to the [bias](https://en.wikipedia.org/wiki/Bias_of_an_estimator) 
of $\hat\beta$ and $\hat\phi$,
and the derivatives of an appropriate transformation of 
(\beta, \phi), which can be computed either analytically 
or numerically 
([Di Caterina and Kosmidis](https://arxiv.org/abs/1710.11217), 
Section 8).

A similar adjustment in location can be performed for 
$\tilde{t}_j$, delivering the corresponding version 
$\tilde{t}_j^*= \tilde{t}_j - \tilde B$.


In the crying babies example, the number of parameters (19) 
is quite large with respect to the sample size (143), thus 
the $N(0,1)$-approximation to the distribution of the Wald 
statistics is likely to be not so accurate. 
In order to better investigate on the significance of lulling, 
the location-adjusted statistics can be numerically computed 
by the `waldi.glm` function via the following code:
```{r echo = TRUE}
t_star <- waldi(babies_ml, which = "lullyes")
t_star
2*(1-pnorm(t_star))

ttilde_star <- waldi(babies_br, which = "lullyes")
ttilde_star
2*(1-pnorm(ttilde_star))
```


With the observed values $t^*=t_{19}^*=1.926$ and 
$\tilde{t}=\tilde{t}_{19}^*=1.906$,
both $p$-values let us conclude that there is no effect of 
lulling on the crying of babies. If one prefers to use 
analytical differentiation, the code to be run is
```{r echo = TRUE}
t_star <- waldi(babies_ml, which = "lullyes", numerical = FALSE)
t_star
2*(1-pnorm(t_star))

ttilde_star <- waldi(babies_br, which = "lullyes", numerical = FALSE)
ttilde_star
2*(1-pnorm(ttilde_star))
```


<!--`glm` objects-->

## Confidence intervals
The inversion of the location-adjusted statistics 
can lead to the construction of confidence intervals
for scalar parameters of interest. This can be
performed by the `waldi_confint` method, which makes
use of parallel computing.

For the crying babies data
```{r echo = TRUE, warning = FALSE}
# Wald-type confidence interval
ci <- waldi_confint(babies_ml, adjust = FALSE, 
                           which = "lullyes")
ci

# location-adjusted Wald-type confidence interval
adj_ci <- waldi_confint(babies_ml, adjust = TRUE, 
                        which = "lullyes")
adj_ci
```

The option `return_values = TRUE` outputs the values 
of the statistics on the grid instead of confidence 
intervals. This is useful for producing plots as the 
ones below:
```{r echo = TRUE, warning = FALSE}
out_wald <- waldi_confint(babies_ml, adjust = FALSE, 
                           which = "lullyes", 
                           return_values = TRUE)
out_waldi <- waldi_confint(babies_ml, adjust = TRUE, 
                          which = "lullyes", 
                          return_values = TRUE)
## Statistics and critical values for 95\% 2-sided intervals
 with(out_waldi, plot(grid, value, type = "l", col = "red", 
                      ylab = "", xlab = expression(gamma)))
 with(out_wald, points(grid, value, type = "l", col = "blue"))
 abline(a = qnorm(0.975), b = 0, lty = 2)
 abline(a = qnorm(0.025), b = 0, lty = 2)
 legend(x = "topright", legend = c(expression(t), expression(t^'*')),
        col = c("blue", "red"), lty = 1)
 
```

```{r echo = TRUE, warning = FALSE}

out_wald <- waldi_confint(babies_br, adjust = FALSE, 
                           which = "lullyes", 
                           return_values = TRUE)
out_waldi <- waldi_confint(babies_br, adjust = TRUE, 
                          which = "lullyes", 
                          return_values = TRUE)
## Statistics and critical values for 95\% 2-sided intervals
 with(out_waldi, plot(grid, value, type = "l", col = "red", 
                      ylab = "", xlab = expression(gamma)))
 with(out_wald, points(grid, value, type = "l", col = "blue"))
 abline(a = qnorm(0.975), b = 0, lty = 2)
 abline(a = qnorm(0.025), b = 0, lty = 2)
 legend(x = "topright", legend = c(expression(tilde(t)), expression(tilde(t)^'*')),
        col = c("blue", "red"), lty = 1)
 
```

## References